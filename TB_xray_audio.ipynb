{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMvqy6EuBeo5zOF3u1JokEy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Quaser001/scribbles_ml/blob/main/TB_xray_audio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "zScVCYXPWkiC",
        "outputId": "35b5502b-ff58-454d-de88-e6beafb38eea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📂 Please upload your kaggle.json file (from Kaggle > Account > Create API Token)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7082bdbe-8eef-4328-821c-f13786dfbe11\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7082bdbe-8eef-4328-821c-f13786dfbe11\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Dataset URL: https://www.kaggle.com/datasets/ruchikashirsath/tb-audio\n",
            "License(s): MIT\n",
            "Downloading tb-audio.zip to /content/data\n",
            " 97% 1.04G/1.08G [00:11<00:00, 94.1MB/s]\n",
            "100% 1.08G/1.08G [00:11<00:00, 103MB/s] \n",
            "Dataset URL: https://www.kaggle.com/datasets/raddar/tuberculosis-chest-xrays-shenzhen\n",
            "License(s): unknown\n",
            "Downloading tuberculosis-chest-xrays-shenzhen.zip to /content/data\n",
            "100% 3.51G/3.51G [00:38<00:00, 19.1MB/s]\n",
            "100% 3.51G/3.51G [00:38<00:00, 99.2MB/s]\n",
            "✅ Datasets ready!\n",
            "TB Audio path: /content/data/tb-audio\n",
            "Shenzhen X-ray path: /content/data/tuberculosis-chest-xrays-shenzhen\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# MODULE 1: Kaggle Data Access + Setup\n",
        "# ================================\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# --- Step 0: Upload Kaggle API key (kaggle.json) ---\n",
        "print(\"📂 Please upload your kaggle.json file (from Kaggle > Account > Create API Token)\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "os.rename(\"kaggle.json\", \"/root/.kaggle/kaggle.json\")\n",
        "os.chmod(\"/root/.kaggle/kaggle.json\", 0o600)\n",
        "\n",
        "# --- Step 1: Install Kaggle API ---\n",
        "!pip install kaggle --quiet\n",
        "\n",
        "# --- Step 2: Download & unzip datasets ---\n",
        "DATA_DIR = \"/content/data\"\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "# TB Audio dataset\n",
        "!kaggle datasets download -d ruchikashirsath/tb-audio -p $DATA_DIR --unzip\n",
        "TB_AUDIO_ROOT = os.path.join(DATA_DIR, \"tb-audio\")\n",
        "\n",
        "# Shenzhen X-ray dataset\n",
        "!kaggle datasets download -d raddar/tuberculosis-chest-xrays-shenzhen -p $DATA_DIR --unzip\n",
        "SHENZHEN_ROOT = os.path.join(DATA_DIR, \"tuberculosis-chest-xrays-shenzhen\")\n",
        "\n",
        "print(\"✅ Datasets ready!\")\n",
        "print(\"TB Audio path:\", TB_AUDIO_ROOT)\n",
        "print(\"Shenzhen X-ray path:\", SHENZHEN_ROOT)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "DATA_DIR = \"/content/data\"\n",
        "\n",
        "# Unzip TB Audio\n",
        "tb_audio_zip = os.path.join(DATA_DIR, \"tb-audio.zip\")\n",
        "tb_audio_dir = os.path.join(DATA_DIR, \"tb-audio\")\n",
        "if os.path.exists(tb_audio_zip):\n",
        "    print(\"🔓 Extracting TB Audio...\")\n",
        "    with zipfile.ZipFile(tb_audio_zip, 'r') as zip_ref:\n",
        "        zip_ref.extractall(tb_audio_dir)\n",
        "\n",
        "# Unzip Shenzhen X-ray\n",
        "shenzhen_zip = os.path.join(DATA_DIR, \"tuberculosis-chest-xrays-shenzhen.zip\")\n",
        "shenzhen_dir = os.path.join(DATA_DIR, \"tuberculosis-chest-xrays-shenzhen\")\n",
        "if os.path.exists(shenzhen_zip):\n",
        "    print(\"🔓 Extracting Shenzhen X-ray...\")\n",
        "    with zipfile.ZipFile(shenzhen_zip, 'r') as zip_ref:\n",
        "        zip_ref.extractall(shenzhen_dir)\n",
        "\n",
        "print(\"✅ Extraction complete!\")\n",
        "\n",
        "# Re-list structure after extraction\n",
        "print(\"\\n📂 TB Audio Dataset Structure\")\n",
        "for root, dirs, files in os.walk(tb_audio_dir):\n",
        "    level = root.replace(tb_audio_dir, \"\").count(os.sep)\n",
        "    indent = \" \" * 2 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    subindent = \" \" * 2 * (level + 1)\n",
        "    for f in files:\n",
        "        print(f\"{subindent}{f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "print(\"📂 Shenzhen X-ray Dataset Structure\")\n",
        "for root, dirs, files in os.walk(shenzhen_dir):\n",
        "    level = root.replace(shenzhen_dir, \"\").count(os.sep)\n",
        "    indent = \" \" * 2 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    subindent = \" \" * 2 * (level + 1)\n",
        "    for f in files:\n",
        "        print(f\"{subindent}{f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iUwtWaaXSLa",
        "outputId": "94cb66d4-3221-47cf-bc14-050e121964a6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Extraction complete!\n",
            "\n",
            "📂 TB Audio Dataset Structure\n",
            "\n",
            "================================================================================\n",
            "\n",
            "📂 Shenzhen X-ray Dataset Structure\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# MODULE 2: Dataset Verification (Corrected Paths)\n",
        "# ==========================================\n",
        "import os\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "# -----------------------\n",
        "# 1) TB AUDIO DATASET\n",
        "# -----------------------\n",
        "TB_AUDIO_ROOT = \"/content/data/Tuberculosis/raw_data/solicited_data\"\n",
        "TB_AUDIO_META = \"/content/data/Tuberculosis/metadata/CODA_TB_Clinical_Meta_Info.csv\"\n",
        "\n",
        "# Load metadata\n",
        "audio_metadata = pd.read_csv(TB_AUDIO_META)\n",
        "\n",
        "# List all audio files in dataset\n",
        "audio_files = [f for f in os.listdir(TB_AUDIO_ROOT) if f.lower().endswith(\".wav\")]\n",
        "\n",
        "print(\"\\n🔍 TB Audio Verification\")\n",
        "print(\"=\"*50)\n",
        "print(\"Metadata entries:\", len(audio_metadata))\n",
        "print(\"Total audio files found:\", len(audio_files))\n",
        "\n",
        "# Assuming 'filename' column contains audio file names\n",
        "if \"filename\" in audio_metadata.columns:\n",
        "    meta_audio_names = set(audio_metadata[\"filename\"].astype(str))\n",
        "    actual_audio_names = set(audio_files)\n",
        "\n",
        "    missing_in_folder = meta_audio_names - actual_audio_names\n",
        "    extra_in_folder = actual_audio_names - meta_audio_names\n",
        "\n",
        "    print(\"Missing files (in metadata but not in folder):\", len(missing_in_folder))\n",
        "    print(\"Extra files (in folder but not in metadata):\", len(extra_in_folder))\n",
        "else:\n",
        "    print(\"⚠️ No 'filename' column found in audio metadata\")\n",
        "\n",
        "# Label distribution (assuming TB column exists, 1 = TB positive, 0 = negative)\n",
        "if \"TB\" in audio_metadata.columns:\n",
        "    print(\"Label distribution:\", Counter(audio_metadata[\"TB\"]))\n",
        "else:\n",
        "    print(\"⚠️ No 'TB' column found in audio metadata\")\n",
        "\n",
        "# -----------------------\n",
        "# 2) SHENZHEN X-RAY DATASET\n",
        "# -----------------------\n",
        "SHENZHEN_ROOT = \"/content/data/images/images\"\n",
        "SHENZHEN_META = \"/content/data/shenzhen_metadata.csv\"\n",
        "\n",
        "# List all X-ray files\n",
        "xray_files = [f for f in os.listdir(SHENZHEN_ROOT) if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
        "\n",
        "print(\"\\n🔍 Shenzhen X-ray Verification\")\n",
        "print(\"=\"*50)\n",
        "print(\"Total X-ray images found:\", len(xray_files))\n",
        "\n",
        "# Load Shenzhen metadata\n",
        "xray_metadata = pd.read_csv(SHENZHEN_META)\n",
        "print(\"Shenzhen metadata shape:\", xray_metadata.shape)\n",
        "print(xray_metadata.head())\n",
        "\n",
        "# Quick label summary if 'Finding' or 'Label' column exists\n",
        "label_col = None\n",
        "for col in [\"Finding\", \"Label\", \"diagnosis\"]:\n",
        "    if col in xray_metadata.columns:\n",
        "        label_col = col\n",
        "        break\n",
        "\n",
        "if label_col:\n",
        "    print(\"X-ray label distribution:\", Counter(xray_metadata[label_col]))\n",
        "else:\n",
        "    print(\"⚠️ No recognizable label column found in Shenzhen metadata\")\n",
        "\n",
        "# -----------------------\n",
        "# ✅ Done\n",
        "print(\"\\n✅ Dataset verification complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iboFF_MJXSGz",
        "outputId": "46201c02-7815-457d-d7ce-e9197b6a1e52"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 TB Audio Verification\n",
            "==================================================\n",
            "Metadata entries: 1105\n",
            "Total audio files found: 9772\n",
            "⚠️ No 'filename' column found in audio metadata\n",
            "⚠️ No 'TB' column found in audio metadata\n",
            "\n",
            "🔍 Shenzhen X-ray Verification\n",
            "==================================================\n",
            "Total X-ray images found: 662\n",
            "Shenzhen metadata shape: (662, 4)\n",
            "            study_id     sex  age findings\n",
            "0  CHNCXR_0001_0.png    Male   45   normal\n",
            "1  CHNCXR_0002_0.png    Male   63   normal\n",
            "2  CHNCXR_0003_0.png  Female   48   normal\n",
            "3  CHNCXR_0004_0.png    Male   58   normal\n",
            "4  CHNCXR_0005_0.png    Male   28   normal\n",
            "⚠️ No recognizable label column found in Shenzhen metadata\n",
            "\n",
            "✅ Dataset verification complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# X-ray metadata\n",
        "xray_meta = pd.read_csv(\"/content/data/shenzhen_metadata.csv\")\n",
        "print(xray_meta.head())\n",
        "print(xray_meta.columns)\n",
        "\n",
        "# Audio metadata\n",
        "audio_meta = pd.read_csv(\"/content/data/Tuberculosis/metadata/manifest.csv\")\n",
        "print(audio_meta.head())\n",
        "print(audio_meta.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6q1MNqaXSCk",
        "outputId": "012326a3-5fc2-463d-bfc7-8592cef8ea7e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            study_id     sex  age findings\n",
            "0  CHNCXR_0001_0.png    Male   45   normal\n",
            "1  CHNCXR_0002_0.png    Male   63   normal\n",
            "2  CHNCXR_0003_0.png  Female   48   normal\n",
            "3  CHNCXR_0004_0.png    Male   58   normal\n",
            "4  CHNCXR_0005_0.png    Male   28   normal\n",
            "Index(['study_id', 'sex', 'age', 'findings'], dtype='object')\n",
            "            ID                                    name  versionNumber  \\\n",
            "0  syn41743692  CODA TB Challenge data dictionary.xlsx              4   \n",
            "1  syn52357041  CODA_TB_additional_variables_train.csv              1   \n",
            "2  syn41604915          CODA_TB_Clinical_Meta_Info.csv              3   \n",
            "3  syn41604939         CODA_TB_Solicited_Meta_Info.csv              2   \n",
            "4  syn41604935       CODA_TB_Longitudnal_Meta_Info.csv              2   \n",
            "\n",
            "                                         contentType  dataFileSizeBytes  \\\n",
            "0  application/vnd.openxmlformats-officedocument....              19702   \n",
            "1                                           text/csv              74624   \n",
            "2                                           text/csv              79794   \n",
            "3                                           text/csv             603623   \n",
            "4                                           text/csv           44151918   \n",
            "\n",
            "   createdBy      createdOn  modifiedBy     modifiedOn     parentId  \\\n",
            "0     273959  1666644216641      273959  1693255659646  syn39711415   \n",
            "1     273959  1693255591072      273959  1693255591072  syn39711415   \n",
            "2    3428786  1666470075290      273959  1666819769998  syn39711415   \n",
            "3    3428786  1666470091295     3428786  1666804395264  syn39711415   \n",
            "4    3428786  1666470089355     3428786  1666804294077  syn39711415   \n",
            "\n",
            "                                        synapseURL  \\\n",
            "0  https://www.synapse.org/#!Synapse:syn41743692.4   \n",
            "1  https://www.synapse.org/#!Synapse:syn52357041.1   \n",
            "2  https://www.synapse.org/#!Synapse:syn41604915.3   \n",
            "3  https://www.synapse.org/#!Synapse:syn41604939.2   \n",
            "4  https://www.synapse.org/#!Synapse:syn41604935.2   \n",
            "\n",
            "                     dataFileMD5Hex  \n",
            "0  f44040212ac6b4c21b9d947ada907013  \n",
            "1  28e36d8e216289a130fd64812face9ff  \n",
            "2  fdac889bc9bca8af1c9926b5325dd8d4  \n",
            "3  58697d303b9c5f7327e3cf87810c742b  \n",
            "4  576c26de53972a6865ca80576a8db7ea  \n",
            "Index(['ID', 'name', 'versionNumber', 'contentType', 'dataFileSizeBytes',\n",
            "       'createdBy', 'createdOn', 'modifiedBy', 'modifiedOn', 'parentId',\n",
            "       'synapseURL', 'dataFileMD5Hex'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torchvision\")\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torchaudio\")\n"
      ],
      "metadata": {
        "id": "FgjeErkRXnX6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Multimodal Training Module (Sanity Check, 2 Epochs)\n",
        "# ================================\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torchaudio\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# -----------------------------\n",
        "# Audio Dataset\n",
        "# -----------------------------\n",
        "class AudioSpectrogramDataset(Dataset):\n",
        "    def __init__(self, df, sr=16000, n_mels=64, max_len=256):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.sr = sr\n",
        "        self.mel = torchaudio.transforms.MelSpectrogram(\n",
        "            sample_rate=sr, n_fft=400, hop_length=160, n_mels=n_mels\n",
        "        )\n",
        "        self.db = torchaudio.transforms.AmplitudeToDB()\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.df.loc[idx, \"filepath\"], self.df.loc[idx, \"label\"]\n",
        "        wav, sr = torchaudio.load(path)\n",
        "        if sr != self.sr:\n",
        "            wav = torchaudio.functional.resample(wav, sr, self.sr)\n",
        "        spec = self.mel(wav)   # (1, n_mels, time)\n",
        "        spec = self.db(spec)\n",
        "        spec = (spec - spec.mean()) / (spec.std() + 1e-6)\n",
        "\n",
        "        # pad or truncate to max_len\n",
        "        if spec.shape[-1] < self.max_len:\n",
        "            pad = self.max_len - spec.shape[-1]\n",
        "            spec = torch.nn.functional.pad(spec, (0, pad))\n",
        "        else:\n",
        "            spec = spec[:, :, :self.max_len]\n",
        "\n",
        "        return spec, torch.tensor(label).long()\n",
        "\n",
        "# -----------------------------\n",
        "# X-ray Dataset\n",
        "# -----------------------------\n",
        "class XrayDataset(Dataset):\n",
        "    def __init__(self, df, root_dir, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.loc[idx]\n",
        "        img_path = os.path.join(self.root_dir, row['filename'])\n",
        "        img = torchvision.io.read_image(img_path).float() / 255.0  # [C,H,W]\n",
        "\n",
        "        # Convert 1 channel → 3 channels\n",
        "        if img.shape[0] == 1:\n",
        "            img = img.repeat(3, 1, 1)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = torch.tensor(row['label']).long()\n",
        "        return img, label\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Prepare Audio Dataset\n",
        "# -----------------------------\n",
        "def prepare_audio_dataset(meta_csvs, audio_root, test_size=0.15, val_size=0.15):\n",
        "    dfs = [pd.read_csv(f) for f in meta_csvs]\n",
        "    meta = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "    if 'filename' not in meta.columns or 'tb_status' not in meta.columns:\n",
        "        raise ValueError(\"Metadata missing required columns 'filename' and 'tb_status'!\")\n",
        "\n",
        "    # drop missing TB labels\n",
        "    meta = meta.dropna(subset=['tb_status'])\n",
        "    meta['filepath'] = meta['filename'].apply(lambda x: os.path.join(audio_root, x))\n",
        "    meta['label'] = meta['tb_status'].astype(int)\n",
        "\n",
        "    train_df, test_df = train_test_split(meta, test_size=test_size, stratify=meta['label'], random_state=42)\n",
        "    train_df, val_df = train_test_split(train_df, test_size=val_size, stratify=train_df['label'], random_state=42)\n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "# -----------------------------\n",
        "# Prepare X-ray Dataset\n",
        "# -----------------------------\n",
        "def prepare_xray_dataset(meta_csv, xray_root, test_size=0.15, val_size=0.15):\n",
        "    meta = pd.read_csv(meta_csv)\n",
        "\n",
        "    if 'study_id' not in meta.columns or 'findings' not in meta.columns:\n",
        "        raise ValueError(\"Metadata missing required columns 'study_id' and 'findings'!\")\n",
        "\n",
        "    # Map TB: normal → 0, anything else → 1\n",
        "    meta['label'] = meta['findings'].apply(lambda x: 0 if str(x).lower() == 'normal' else 1)\n",
        "    meta['filename'] = meta['study_id'].astype(str)  # match file naming\n",
        "\n",
        "    train_df, test_df = train_test_split(meta, test_size=test_size, stratify=meta['label'], random_state=42)\n",
        "    train_df, val_df = train_test_split(train_df, test_size=val_size, stratify=train_df['label'], random_state=42)\n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "# -----------------------------\n",
        "# Build Models\n",
        "# -----------------------------\n",
        "def build_resnet_audio(n_classes=2):\n",
        "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "    model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    model.fc = nn.Linear(model.fc.in_features, n_classes)\n",
        "    return model.to(device)\n",
        "\n",
        "def build_resnet_xray(n_classes=2):\n",
        "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "    model.fc = nn.Linear(model.fc.in_features, n_classes)\n",
        "    return model.to(device)\n",
        "\n",
        "# -----------------------------\n",
        "# Training Loop\n",
        "# -----------------------------\n",
        "def train_model(model, train_loader, val_loader, epochs=2, lr=1e-3, save_path=\"best_model.pt\"):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    best_f1 = 0.0\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        y_true, y_pred = [], []\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = criterion(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()*x.size(0)\n",
        "            y_true.extend(y.cpu().numpy())\n",
        "            y_pred.extend(out.argmax(dim=1).cpu().numpy())\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_acc = accuracy_score(y_true, y_pred)\n",
        "        train_f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        y_true, y_pred = [], []\n",
        "        with torch.no_grad():\n",
        "            for x, y in val_loader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                out = model(x)\n",
        "                loss = criterion(out, y)\n",
        "                val_loss += loss.item()*x.size(0)\n",
        "                y_true.extend(y.cpu().numpy())\n",
        "                y_pred.extend(out.argmax(dim=1).cpu().numpy())\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_acc = accuracy_score(y_true, y_pred)\n",
        "        val_f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "        epoch_time = time.time() - start_time\n",
        "        print(f\"Epoch {epoch}/{epochs} | Train Loss {train_loss:.4f} Acc {train_acc:.4f} F1 {train_f1:.4f} | \"\n",
        "              f\"Val Loss {val_loss:.4f} Acc {val_acc:.4f} F1 {val_f1:.4f} | Time {epoch_time:.2f}s\")\n",
        "\n",
        "        if val_f1 > best_f1:\n",
        "            best_f1 = val_f1\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(\"-> New best model saved!\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# ==============================\n",
        "# Run Audio Pipeline\n",
        "# ==============================\n",
        "audio_meta_csvs = [\n",
        "    \"/content/data/Tuberculosis/metadata/X_train_Fold_1.csv\",\n",
        "    \"/content/data/Tuberculosis/metadata/X_train_Fold_2.csv\"\n",
        "]  # only existing files\n",
        "audio_root = \"/content/data/Tuberculosis/raw_data/solicited_data\"\n",
        "\n",
        "train_df_a, val_df_a, test_df_a = prepare_audio_dataset(audio_meta_csvs, audio_root)\n",
        "train_loader_a = DataLoader(AudioSpectrogramDataset(train_df_a), batch_size=16, shuffle=True)\n",
        "val_loader_a = DataLoader(AudioSpectrogramDataset(val_df_a), batch_size=16, shuffle=False)\n",
        "\n",
        "audio_model = build_resnet_audio()\n",
        "print(\"\\n--- Training Audio Model ---\")\n",
        "audio_model = train_model(audio_model, train_loader_a, val_loader_a, epochs=2, save_path=\"audio_best.pt\")\n",
        "\n",
        "# ==============================\n",
        "# Run X-ray Pipeline\n",
        "# ==============================\n",
        "xray_csv = \"/content/data/shenzhen_metadata.csv\"\n",
        "xray_root = \"/content/data/images/images\"\n",
        "\n",
        "train_df_x, val_df_x, test_df_x = prepare_xray_dataset(xray_csv, xray_root)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224))\n",
        "])\n",
        "\n",
        "train_loader_x = DataLoader(XrayDataset(train_df_x, xray_root, transform), batch_size=16, shuffle=True)\n",
        "val_loader_x = DataLoader(XrayDataset(val_df_x, xray_root, transform), batch_size=16, shuffle=False)\n",
        "\n",
        "xray_model = build_resnet_xray()\n",
        "print(\"\\n--- Training X-ray Model ---\")\n",
        "xray_model = train_model(xray_model, train_loader_x, val_loader_x, epochs=2, save_path=\"xray_best.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu50unWeXnVD",
        "outputId": "5dc44974-bb67-4940-db9a-1139990c5b13"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "\n",
            "--- Training Audio Model ---\n",
            "Epoch 1/2 | Train Loss 0.5935 Acc 0.6866 F1 0.6358 | Val Loss 0.5786 Acc 0.7020 F1 0.5791 | Time 75.37s\n",
            "-> New best model saved!\n",
            "Epoch 2/2 | Train Loss 0.5698 Acc 0.7011 F1 0.6588 | Val Loss 0.6063 Acc 0.6418 F1 0.6570 | Time 74.89s\n",
            "-> New best model saved!\n",
            "\n",
            "--- Training X-ray Model ---\n",
            "Epoch 1/2 | Train Loss 0.5867 Acc 0.7841 F1 0.7841 | Val Loss 0.5697 Acc 0.7647 F1 0.7637 | Time 105.62s\n",
            "-> New best model saved!\n",
            "Epoch 2/2 | Train Loss 0.3277 Acc 0.8700 F1 0.8693 | Val Loss 0.9422 Acc 0.7882 F1 0.7856 | Time 103.90s\n",
            "-> New best model saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# Multimodal Training Module (20 Epochs)\n",
        "# ==============================\n",
        "\n",
        "# -----------------------------\n",
        "# Audio Training (20 epochs)\n",
        "# -----------------------------\n",
        "print(\"\\n=== Training Audio Model for 20 Epochs ===\")\n",
        "audio_model_20 = build_resnet_audio()  # new model instance\n",
        "audio_model_20 = train_model(\n",
        "    audio_model_20,\n",
        "    train_loader_a,\n",
        "    val_loader_a,\n",
        "    epochs=15,\n",
        "    lr=1e-3,\n",
        "    save_path=\"audio_best_20.pt\"\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# X-ray Training (20 epochs)\n",
        "# -----------------------------\n",
        "print(\"\\n=== Training X-ray Model for 20 Epochs ===\")\n",
        "xray_model_20 = build_resnet_xray()  # new model instance\n",
        "xray_model_20 = train_model(\n",
        "    xray_model_20,\n",
        "    train_loader_x,\n",
        "    val_loader_x,\n",
        "    epochs=15,\n",
        "    lr=1e-3,\n",
        "    save_path=\"xray_best_20.pt\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dTuiufg4bPh",
        "outputId": "ded549af-c9cc-4834-d5be-b05bf71f38cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Training Audio Model for 20 Epochs ===\n",
            "Epoch 1/20 | Train Loss 0.6075 Acc 0.6865 F1 0.6296 | Val Loss 0.5719 Acc 0.7178 F1 0.6747 | Time 75.25s\n",
            "-> New best model saved!\n",
            "Epoch 2/20 | Train Loss 0.5653 Acc 0.7061 F1 0.6598 | Val Loss 0.5598 Acc 0.7028 F1 0.5850 | Time 76.20s\n",
            "Epoch 3/20 | Train Loss 0.5514 Acc 0.7131 F1 0.6755 | Val Loss 0.5574 Acc 0.7239 F1 0.7036 | Time 75.20s\n",
            "-> New best model saved!\n",
            "Epoch 4/20 | Train Loss 0.5355 Acc 0.7223 F1 0.6982 | Val Loss 0.5961 Acc 0.7126 F1 0.6905 | Time 74.92s\n",
            "Epoch 5/20 | Train Loss 0.5088 Acc 0.7474 F1 0.7319 | Val Loss 0.5436 Acc 0.7494 F1 0.7208 | Time 76.90s\n",
            "-> New best model saved!\n",
            "Epoch 6/20 | Train Loss 0.4796 Acc 0.7659 F1 0.7553 | Val Loss 0.5125 Acc 0.7562 F1 0.7516 | Time 75.33s\n",
            "-> New best model saved!\n",
            "Epoch 7/20 | Train Loss 0.4274 Acc 0.8041 F1 0.7985 | Val Loss 0.5892 Acc 0.7126 F1 0.7241 | Time 75.38s\n",
            "Epoch 8/20 | Train Loss 0.3879 Acc 0.8315 F1 0.8291 | Val Loss 0.4431 Acc 0.7976 F1 0.7913 | Time 76.35s\n",
            "-> New best model saved!\n",
            "Epoch 9/20 | Train Loss 0.3129 Acc 0.8676 F1 0.8662 | Val Loss 0.5042 Acc 0.8051 F1 0.8093 | Time 75.49s\n",
            "-> New best model saved!\n",
            "Epoch 10/20 | Train Loss 0.2476 Acc 0.8993 F1 0.8988 | Val Loss 0.5288 Acc 0.8209 F1 0.8172 | Time 74.82s\n",
            "-> New best model saved!\n",
            "Epoch 11/20 | Train Loss 0.1807 Acc 0.9309 F1 0.9308 | Val Loss 0.4892 Acc 0.8315 F1 0.8289 | Time 75.80s\n",
            "-> New best model saved!\n",
            "Epoch 12/20 | Train Loss 0.1378 Acc 0.9479 F1 0.9479 | Val Loss 0.5042 Acc 0.8382 F1 0.8360 | Time 75.26s\n",
            "-> New best model saved!\n",
            "Epoch 13/20 | Train Loss 0.0999 Acc 0.9641 F1 0.9641 | Val Loss 0.5142 Acc 0.8510 F1 0.8489 | Time 75.35s\n",
            "-> New best model saved!\n",
            "Epoch 14/20 | Train Loss 0.0843 Acc 0.9700 F1 0.9700 | Val Loss 0.5932 Acc 0.8412 F1 0.8423 | Time 75.36s\n",
            "Epoch 15/20 | Train Loss 0.0632 Acc 0.9758 F1 0.9758 | Val Loss 0.7836 Acc 0.8412 F1 0.8374 | Time 75.78s\n",
            "Epoch 16/20 | Train Loss 0.0641 Acc 0.9773 F1 0.9773 | Val Loss 0.6725 Acc 0.8360 F1 0.8347 | Time 74.87s\n",
            "Epoch 17/20 | Train Loss 0.0493 Acc 0.9829 F1 0.9829 | Val Loss 0.6135 Acc 0.8503 F1 0.8461 | Time 75.50s\n",
            "Epoch 18/20 | Train Loss 0.0342 Acc 0.9892 F1 0.9892 | Val Loss 0.6919 Acc 0.8299 F1 0.8312 | Time 74.90s\n",
            "Epoch 19/20 | Train Loss 0.0366 Acc 0.9876 F1 0.9876 | Val Loss 0.6724 Acc 0.8465 F1 0.8430 | Time 75.06s\n",
            "Epoch 20/20 | Train Loss 0.0356 Acc 0.9870 F1 0.9870 | Val Loss 0.7011 Acc 0.8480 F1 0.8470 | Time 75.32s\n",
            "\n",
            "=== Training X-ray Model for 20 Epochs ===\n",
            "Epoch 1/20 | Train Loss 0.6161 Acc 0.7484 F1 0.7464 | Val Loss 0.8636 Acc 0.7647 F1 0.7646 | Time 105.27s\n",
            "-> New best model saved!\n",
            "Epoch 2/20 | Train Loss 0.3802 Acc 0.8344 F1 0.8327 | Val Loss 0.5947 Acc 0.7765 F1 0.7765 | Time 104.80s\n",
            "-> New best model saved!\n",
            "Epoch 3/20 | Train Loss 0.3322 Acc 0.8658 F1 0.8657 | Val Loss 0.6515 Acc 0.7176 F1 0.7114 | Time 105.62s\n",
            "Epoch 4/20 | Train Loss 0.3060 Acc 0.8532 F1 0.8532 | Val Loss 1.1080 Acc 0.7294 F1 0.7213 | Time 105.44s\n",
            "Epoch 5/20 | Train Loss 0.2414 Acc 0.8910 F1 0.8909 | Val Loss 1.6750 Acc 0.5176 F1 0.3770 | Time 106.16s\n",
            "Epoch 6/20 | Train Loss 0.2281 Acc 0.9182 F1 0.9182 | Val Loss 2.2760 Acc 0.5412 F1 0.4139 | Time 104.74s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def list_folders(base_path, level=1, prefix=\"\"):\n",
        "    if not os.path.exists(base_path):\n",
        "        print(f\"Path not found: {base_path}\")\n",
        "        return\n",
        "    for root, dirs, files in os.walk(base_path):\n",
        "        depth = root.replace(base_path, \"\").count(os.sep)\n",
        "        if depth < level:\n",
        "            for d in dirs:\n",
        "                print(f\"[DIR] {os.path.join(root, d)}\")\n",
        "        else:\n",
        "            # Don’t go deeper than the specified level\n",
        "            dirs[:] = []\n",
        "\n",
        "# 🔹 Change this to explore deeper if needed\n",
        "list_folders(\"/content/data/Tuberculosis\", level=3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwwvEubNXnQp",
        "outputId": "75c550c6-2381-4dfa-a6b2-6ecfdfefefcf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DIR] /content/data/Tuberculosis/metadata\n",
            "[DIR] /content/data/Tuberculosis/raw_data\n",
            "[DIR] /content/data/Tuberculosis/.ipynb_checkpoints\n",
            "[DIR] /content/data/Tuberculosis/raw_data/solicited_data\n",
            "[DIR] /content/data/Tuberculosis/raw_data/longitudinal_data\n",
            "[DIR] /content/data/Tuberculosis/raw_data/longitudinal_data/longitudinal_1\n",
            "[DIR] /content/data/Tuberculosis/raw_data/longitudinal_data/longitudinal_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pS_q2dETXnOD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}